{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "48Z8UktIE-MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Portugues/modelo_fakenews_final.zip\" -d \"/content/modelo_fakenews_final\""
      ],
      "metadata": {
        "id": "tBXDbxGeGW3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "modelo_dir = \"/content/modelo_fakenews_final/modelo_fakenews_final/checkpoint-7450\"\n",
        "\n",
        "# Carrega o tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelo_dir, model_type=\"bert\")\n",
        "\n",
        "# Carrega o modelo treinado\n",
        "model = AutoModelForSequenceClassification.from_pretrained(modelo_dir)\n",
        "\n",
        "# Coloca em modo de avaliação\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "oFmiCr_6K9LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "modelo_dir = \"/content/modelo_fakenews_final/modelo_fakenews_final/checkpoint-7450\"\n",
        "csv_path = \"/content/drive/MyDrive/Portugues/test_dataset.csv\"\n",
        "\n",
        "# Define o dispositivo de execução GPU (cuda)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Carrega o tokenizer e o modelo\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelo_dir, model_type=\"bert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(modelo_dir).to(device)\n",
        "model.eval()  #modo de avaliação\n",
        "\n",
        "# Lê o dataset de teste\n",
        "df_test = pd.read_csv(csv_path, sep=\";\", encoding=\"utf-8\")\n",
        "\n",
        "# F faz previsões em lotes p evitar sobrecarga de memória\n",
        "def predict_in_batches(texts, batch_size=200):\n",
        "    preds = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=256,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        # Desativa o cálculo  gradiente e gera previsões\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            batch_preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "            preds.extend(batch_preds)\n",
        "\n",
        "    return preds\n",
        "\n",
        "\n",
        "print(\"Gerando predições\")\n",
        "preds = predict_in_batches(df_test[\"texto\"].tolist(), batch_size=200)\n",
        "\n",
        "# Calcula métricas de desempenho\n",
        "y_true = df_test[\"label\"].values\n",
        "print(\"\\nAcurácia:\", round(accuracy_score(y_true, preds), 4))\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_true, preds, target_names=[\"FAKE\", \"REAL\"]))\n",
        "\n",
        "# Identifica e mostra as amostras que o modelo errou\n",
        "df_test[\"predito\"] = preds\n",
        "erros = df_test[df_test[\"predito\"] != df_test[\"label\"]]\n",
        "print(f\"\\nTotal de erros: {len(erros)} de {len(df_test)} amostras\")\n",
        "\n",
        "# Cria uma matriz de confusão\n",
        "cm = confusion_matrix(y_true, preds)\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Falso Positivo\", \"Verdadeiro Positivo\"],\n",
        "            yticklabels=[\"Verdadeiro Negativo\", \"Falso Negativo\"])\n",
        "plt.title(\"Matriz de Confusão - BERTimbau\")\n",
        "plt.xlabel(\"Previsão do Modelo\")\n",
        "plt.ylabel(\"Valor Real\")\n",
        "plt.show()\n",
        "\n",
        "# Salva as predições completas\n",
        "output_path = \"/content/drive/MyDrive/Portugues/resultados_bert.csv\"\n",
        "df_test.to_csv(output_path, sep=\";\", index=False, encoding=\"utf-8-sig\")\n",
        "print(f\"Arquivo de predições salvo em: {output_path}\")\n"
      ],
      "metadata": {
        "id": "VzZVwPuQGk5P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}